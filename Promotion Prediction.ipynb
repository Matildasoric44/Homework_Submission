{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promotion Dataset\n",
    "\n",
    "Multiple attributes have been provided around Employee's past and current performance along with demographics.\n",
    "\n",
    "Features:\n",
    "\n",
    "- employee_id: Unique ID for employee\n",
    "- department: Department of employee\n",
    "- region: Region of employment (unordered)\n",
    "- education: Education Level\n",
    "- gender: Gender of Employee\n",
    "- recruitment_channel: Channel of recruitment for employee\n",
    "- no_ of_ trainings: no of other trainings completed in previous year on soft skills, technical skills etc.\n",
    "- age: Age of Employee\n",
    "- previous_ year_ rating: Employee Rating for the previous year\n",
    "- length_ of_ service: Length of service in years\n",
    "- awards_ won?: if awards won during previous year then 1 else 0\n",
    "- avg_ training_ score: Average score in current training evaluations\n",
    "- is_promoted: (Target) Recommended for promotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file into a pandas DataFrame called `promotions_df`\n",
    "promotions_df =  pd.read_csv(\"../Resources/promotions.csv\")\n",
    "promotions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `X` and `y` datasets\n",
    "\n",
    "X = promotions_df.drop('is_promoted', axis=1)\n",
    "y = promotions_df['is_promoted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encode the `X` data into numerical features\n",
    "X = pd.get_dummies(X,prefix=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler() model and fit it to the training data\n",
    "scaler = StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and testing data by using the scaler model\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Random Forest to predict promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Random Forest Classifier model with 500 trees and print training and testing scores\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(X_train_scaled, y_train)\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Training Score: {clf.score(X_train_scaled, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance from the fitted random forest model\n",
    "\n",
    "features = clf.feature_importances_\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the feature importance \n",
    "px.bar(x=X.columns, y=features,labels={\"x\":\"Features\",\"y\":\"Score Features\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perofrm feature selection using sklearns SelectFromModel module\n",
    "sel = SelectFromModel(clf)\n",
    "sel.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `.transofrm()` function to transform the scaled `X_train` and `X_test` data \n",
    "# to return a new dataframe with only the features from the previous step\n",
    "X_train_new_scaled = scaler.transform(X_train)\n",
    "X_test_new_scaled = scaler.transform(X_test)\n",
    "\n",
    "selFeatures = pd.DataFrame(X_train_new_scaled)\n",
    "selFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a model and print training and testing scores with 500 trees\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(selFeatures, y_train)\n",
    "y_pred = clf.predict(X_test_new_scaled)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Training Score: {clf.score(selFeatures, y_train)}')\n",
    "print(f'Testing Score: {clf.score(X_test_new_scaled, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use K Nearest Neighbors to predict promotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a K Nearest Neighbors model and loop through different k values of 1 to 20 by 2\n",
    "# to find which has the highest accuracy.\n",
    "# Note: We use only odd numbers because we don't want any ties.\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 20, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results of the train and test scores from the previous loop   \n",
    "plt.plot(range(1, 20, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 20, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the `k` that provides the best accuracy where the classifier starts to stablize\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "print('k=9 Test Acc: %.3f' % knn.score(X_test_scaled, y_test))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
